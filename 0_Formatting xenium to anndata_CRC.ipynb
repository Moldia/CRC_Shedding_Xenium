{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PURPOSE OF THE NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to format Xenium data to adata and, if needed, keep only nuclear information of reads a certain distance from the nuclei."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from scipy.io import mmread\n",
    "#import xb.formatting as xf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import shutil\n",
    "import os.path\n",
    "from scipy.io import mmread\n",
    "import tifffile as tf\n",
    "from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
    "from anndata import AnnData\n",
    "import json\n",
    "#from xb.formatting import format_background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We input the path wher our original xenium data is and we use ```format_xenium_data``` to transform the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_xenium_adata_2023_parquet(path,tag,output_path):\n",
    "    #decompress\n",
    "    if os.path.isfile(path+'/transcripts.csv')==False:\n",
    "        with gzip.open(path+'/transcripts.csv.gz', 'rb') as f_in:\n",
    "            with open(path+'/transcripts.csv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    if os.path.isfile(path+'/cell_feature_matrix/barcodes.tsv')==False:\n",
    "        with gzip.open(path+'/cell_feature_matrix/barcodes.tsv.gz', 'rb') as f_in:\n",
    "            with open(path+'/cell_feature_matrix/barcodes.tsv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    if os.path.isfile(path+'/cell_feature_matrix/features.tsv')==False:\n",
    "        with gzip.open(path+'/cell_feature_matrix/features.tsv.gz', 'rb') as f_in:\n",
    "            with open(path+'/cell_feature_matrix/features.tsv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    if os.path.isfile(path+'/cell_feature_matrix/matrix.mtx')==False:\n",
    "        with gzip.open(path+'/cell_feature_matrix/matrix.mtx.gz', 'rb') as f_in:\n",
    "            with open(path+'/cell_feature_matrix/matrix.mtx', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "    if os.path.isfile(path+'/cells.csv')==False:\n",
    "        with gzip.open(path+'/cells.csv.gz', 'rb') as f_in:\n",
    "            with open(path+'/cells.csv', 'wb') as f_out:\n",
    "                shutil.copyfileobj(f_in, f_out)\n",
    "    a = mmread(path+'/cell_feature_matrix/matrix.mtx')\n",
    "    ad=a.todense()\n",
    "    cell_info=pd.read_csv(path+r\"/cells.csv\")\n",
    "    features=pd.read_csv(path+'/cell_feature_matrix/features.tsv',sep='\\t',header=None,index_col=0)\n",
    "    barcodes=pd.read_csv(path+'/cell_feature_matrix/barcodes.tsv',header=None,index_col=0)\n",
    "    adata=sc.AnnData(ad.transpose(),obs=cell_info,var=features)\n",
    "    adata.var.index.name='index'\n",
    "    adata.var.columns=['gene_id','reason_of_inclusion']\n",
    "    import json\n",
    "    # Opening JSON file\n",
    "    f = open(path+'/gene_panel.json')\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "    # Iterating through the json\n",
    "    # list\n",
    "    geness=[]\n",
    "    idss=[]\n",
    "    descriptorss=[]\n",
    "    for r in range(len(data['payload']['targets'])):\n",
    "        geness.append(data['payload']['targets'][r]['type']['data']['name'])\n",
    "        try:\n",
    "            idss.append(data['payload']['targets'][r]['type']['data']['id'])\n",
    "        except:\n",
    "            idss.append('newid_'+str(r)) \n",
    "        try:\n",
    "            descriptorss.append(data['payload']['targets'][r]['type']['descriptor'])\n",
    "        except:\n",
    "            descriptorss.append('other')\n",
    "    # Closing file\n",
    "    f.close()\n",
    "\n",
    "    dict_inpanel=dict(zip(geness,descriptorss))\n",
    "    dict_ENSEMBL=dict(zip(geness,idss))\n",
    "    adata.var['Ensembl ID']=adata.var['gene_id'].map(dict_ENSEMBL)\n",
    "    adata.var['in_panel']=adata.var['gene_id'].map(dict_inpanel)\n",
    "    transcripts=pd.read_parquet(path+'/transcripts.parquet')\n",
    "    adata.uns['spots']=transcripts\n",
    "    try:\n",
    "        UMAP=pd.read_csv(path+'/analysis/umap/gene_expression_2_components/projection.csv',index_col=0)\n",
    "        adata.obsm['X_umap']=np.array(UMAP)\n",
    "        TSNE=pd.read_csv(path+'/analysis/tsne/gene_expression_2_components/projection.csv',index_col=0)\n",
    "        adata.obsm['X_tsne']=np.array(TSNE)\n",
    "        PCA=pd.read_csv(path+'/analysis/PCA/gene_expression_10_components/projection.csv',index_col=0)\n",
    "        adata.obsm['X_pca']=np.array(PCA)\n",
    "        clusters=pd.read_csv(path+'/analysis/clustering/gene_expression_graphclust/clusters.csv',index_col=0)\n",
    "        adata.obs['graph_clusters']=list(clusters['Cluster'].astype(str))\n",
    "        kmeans2=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans2_clusters']=list(kmeans2['Cluster'].astype(str))\n",
    "        kmeans3=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans3_clusters']=list(kmeans3['Cluster'].astype(str))\n",
    "        kmeans4=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans4_clusters']=list(kmeans4['Cluster'].astype(str))\n",
    "        kmeans5=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans5_clusters']=list(kmeans5['Cluster'].astype(str))\n",
    "        kmeans6=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans6_clusters']=list(kmeans6['Cluster'].astype(str))\n",
    "        kmeans7=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans7_clusters']=list(kmeans7['Cluster'].astype(str))\n",
    "        kmeans8=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans8_clusters']=list(kmeans8['Cluster'].astype(str))\n",
    "        kmeans9=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans9_clusters']=list(kmeans9['Cluster'].astype(str))\n",
    "        kmeans10=pd.read_csv(path+'/analysis/clustering/gene_expression_kmeans_2_clusters/clusters.csv',index_col=0)\n",
    "        adata.obs['kmeans10_clusters']=list(kmeans10['Cluster'].astype(str))\n",
    "    except:\n",
    "        print('UMAP and clusters_could not be recovered')\n",
    "    adata.X=sp.sparse.csr_matrix(adata.X)\n",
    "    adata.uns['spots']=adata.uns['spots'].fillna(0)\n",
    "    adata.uns['spots']['fov_name']=adata.uns['spots']['fov_name'].astype(str)\n",
    "    adata.write(output_path+tag+'.h5ad')\n",
    "    return adata\n",
    "\n",
    "def keep_nuclei_and_quality(adata1,distance_to_nucleus=1,qvmin=20):\n",
    "\n",
    "    subset1=adata1.uns['spots'].loc[adata1.uns['spots']['nucleus_distance']<distance_to_nucleus,:]\n",
    "    subset1=subset1[subset1['qv']>qvmin]\n",
    "    ct1=pd.crosstab(subset1['cell_id'],subset1['feature_name'])\n",
    "    adataobs=adata1.obs.loc[adata1.obs['cell_id'].isin(ct1.index),:]\n",
    "    av=adata1.var.index[adata1.var.index.isin(ct1.columns)]#.isin(adata1.var.index)\n",
    "    ct1=ct1.loc[:,av]\n",
    "    adataobs.index=adataobs['cell_id']\n",
    "    adataobs.index.name='ind'\n",
    "    ct1=ct1.loc[ct1.index.isin(adataobs['cell_id']),:]\n",
    "    adata1nuc=sc.AnnData(np.array(ct1),obs=adataobs)#,var=adata1.var)\n",
    "    adata1nuc.var.index=ct1.columns\n",
    "    return adata1nuc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the path where our raw data is, in ´genpath´. We also define where to save all the other outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "genpath='/media/sergio/Meninges/CRC/Xenium/'\n",
    "output_path=r'/media/sergio/Meninges/CRC/xenium_processing/unprocessed_adata/' # path where to save the normal adata\n",
    "nuclei_path=r'/media/sergio/Meninges/CRC/xenium_processing/nuclei_adata/' # path where to save the nuclei adata\n",
    "combined_path=r'/media/sergio/Meninges/CRC/xenium_processing/combined_adata/' # path where to save combined all filtered AnnData objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we format each dataset in the path defined in genpath. This might take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output-XETG00213__0021489__Region_1__20240125__150400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/anaconda3/envs/xb/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n",
      "/home/sergio/anaconda3/envs/xb/lib/python3.7/site-packages/anndata/_core/anndata.py:121: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP and clusters_could not be recovered\n",
      "output-XETG00213__0021489__Region_2__20240125__150400\n",
      "UMAP and clusters_could not be recovered\n",
      "output-XETG00213__0021492__Region_1__20240125__150400\n",
      "UMAP and clusters_could not be recovered\n",
      "output-XETG00213__0021492__Region_2__20240125__150400\n",
      "UMAP and clusters_could not be recovered\n"
     ]
    }
   ],
   "source": [
    "fls=os.listdir(genpath)\n",
    "fls_filt=[fi for fi in fls if not '.zip' in fi]\n",
    "for f in fls_filt:\n",
    "    print(f)\n",
    "    path=genpath+f\n",
    "    tag=f.split('__')[1]+'_'+f.split('__')[2]\n",
    "    ad=format_xenium_adata_2023_parquet(path,tag,output_path)\n",
    "    format_background(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep only nuclear genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read all the files we created in the previous step and extract only the reads with a minimum quality of 20 and situated in the nuclei (with a nuclei distance <0.1). In xenium's data, all reads at a distance to nucleus of 0 are, indeed, in the nuclei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0021489_Region_1.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/anaconda3/envs/xb/lib/python3.7/site-packages/ipykernel_launcher.py:111: FutureWarning: X.dtype being converted to np.float32 from int64. In the next version of anndata (0.9) conversion will not be automatic. Pass dtype explicitly to avoid this warning. Pass `AnnData(X, dtype=X.dtype, ...)` to get the future behavour.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0021489_Region_2.h5ad\n",
      "0021492_Region_1.h5ad\n",
      "0021492_Region_2.h5ad\n"
     ]
    }
   ],
   "source": [
    "files=os.listdir(output_path)\n",
    "allf=[]\n",
    "for f in files[:]:\n",
    "    print(f)\n",
    "    adata1=sc.read(output_path+f)\n",
    "    adata1.var.index=adata1.var['gene_id']\n",
    "    adata_f1=keep_nuclei_and_quality(adata1,distance_to_nucleus=0.1,qvmin=20)\n",
    "    adata_f1.obs['sample']=f.split('.')[0]\n",
    "    adata_f1.write(nuclei_path+f)\n",
    "    allf.append(adata_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we concatenate all the datasets into one adata object, saved in the combined path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/anaconda3/envs/xb/lib/python3.7/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"obs\")\n"
     ]
    }
   ],
   "source": [
    "adata=sc.concat(allf)\n",
    "adata.write(combined_path+'adata_input.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
